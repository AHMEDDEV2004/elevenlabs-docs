---
title: ""
description: ""
---

When cloning a voice, it's important to consider that the AI has been trained on audiobooks. The AI can handle some accents, like American and British very well, but it can also replicate many other accents, but it is best at those two because of what it encountered during its training. If you have an accent that falls outside of the more common, the AI might have a hard time replicating your voice perfectly and may give you a slightly different accent.

The audio quality is more important than the length of the audio. About 1-2 minutes of clear audio without any reverb, artefacts, or background noise of any kind seems to be the sweet spot. The AI will try to mimic the speed of the person talking as well as the inflexions, so giving it a slower-speaking voice with clear pronunciation seems to give better and more natural results.

Another important thing to keep in mind is that the AI will try to replicate the performance of the voice you provide. If you talk in a slow, monotone voice without much emotion, that is what the AI will mimic. On the other hand, if you talk quickly with much emotion, that is what the AI will try to replicate.

- Audio quality is the most important aspect to consider when getting a proper clone.
- Audio length is less important than quality but still plays an important role up to a certain point. At a minimum, input audio should be 1min long. Avoid adding beyond 3 minutes; this will  yield little improvement and can, in some cases, even be detrimental to the clone.
- Root Mean Square (RMS) volume of the audio also plays a role in getting higher-quality clones.
- Feeding the AI audio that is very dynamic, meaning wide fluctuations in pitch and volume, will yield less predictable results.

If you are unsure about what is permissible from a legal standpoint, please consult the [Terms of Service](https://beta.elevenlabs.io/safety) for more information.