---
title: "Introduction"
description: "Learn how to generate speech from text"
---

<CardGroup cols={2}>
  <Card title="Set up an account" icon="user" href="https://beta.elevenlabs.io/sign-up">
    Get access to the best TTS service in the world!
  </Card>
  <Card title="Get API key" icon="key"href="authentication">
    Experience seamless integration with our API using an API key!
  </Card>
  <Card title="Start developing!" icon="code" href="text-to-speech">
    Get started with our Text to Speech guide featuring sample code examples!
  </Card>
  <Card title="Upgrade subscription" icon="rectangle-pro" href="https://beta.elevenlabs.io/subscription">
    Unlock more characters and cool features!
  </Card>
</CardGroup>



The [Text-To-Speech (TTS)](https://docs.elevenlabs.io/api-reference/text-to-speech) endpoint transforms text into speech in a given voice.
The input consists of text, voice and voice settings with an option to specify model and language.

We have created a set of pre-made, ‘default’ voices which everyone can use. To get those voices use
`GET /v1/voices` without the API key as described in the [Get Voices](/api-reference/voices)
endpoint documentation. If you provide the API key, endpoint will return both the premade voices
and the voices you added. This endpoint is important as it returns a voice ID for each voice.
You will need this ID to query the TTS endpoint.

Now that you know how to get all the voices, let’s see how to create a new one.
First, you need to get samples for the voice you want to add. Since no model training is involved,
there is no need to provide long samples - if they have a combined length of ≈1 min this is enough.
Their quality plays the biggest role. Once you have the samples ready, choose a name,
labels describing the voice (accent, gender, tone etc.) and create it as described in 
[Add Voice](/api-reference/voices-add) endpoint documentation. If you want to edit the samples,
labels or the name of the voice, you can do this with the `POST /v1/voices/{voice_id}/edit`
endpoint. Find more information, see [here](/api-reference/voices-edit).

Once you have your voice ready, get its ID from the [voices endpoint](/api-reference/voices),
and you’re ready to query our TTS endpoint. First you need to decide whether you want to use
the streaming response or not. In general, we recommend streaming unless your client doesn’t
support it. Second, you need to choose your voice settings. We recommend using
[default voice settings](/api-reference/voices-settings-default) before experimenting with
the expressivity and similarity settings. In the third optional step you can specify the model
to be used for speech generation. You can get a full list of available models
by querying [models](/api-reference/models-get) endpoint.
You can find the streaming endpoint documentation [here](/api-reference/text-to-speech-stream)
and the regular endpoint documentation [here](/api-reference/text-to-speech).

We store each audio you generate together with other metadata in your personal history.
You can retrieve all your history items via [/v1/history](/api-reference/history) endpoint.
We also provide endpoints for [retrieving audio](/api-reference/history-audio),
[deletion](/api-reference/history-delete) and [download of history items](/api-reference/history-download).

Here is a `python` example implementing our guide. Get your [XI API Key](authentication) first
and try it out!
```python
import requests

# streaming chunk size
CHUNK_SIZE = 1024

XI_API_KEY = "<xi-api-key>"
VOICE_SAMPLE_PATH1 = "<path-to-file>"
VOICE_SAMPLE_PATH2 = "<path-to-file>"
OUTPUT_PATH = "<path-to-file>"

add_voice_url = "https://api.elevenlabs.io/v1/voices/add"

headers = {
  "Accept": "application/json",
  "xi-api-key": XI_API_KEY
}

data = {
    'name': 'Voice name',
    'labels': '{"accent": "American", "gender": "Female"}',
    'description': 'An old American male voice with a slight hoarseness in his throat. Perfect for news.'
}

files = [
    ('files', ('sample1.mp3', open(VOICE_SAMPLE_PATH1, 'rb'), 'audio/mpeg')),
    ('files', ('sample2.mp3', open(VOICE_SAMPLE_PATH2, 'rb'), 'audio/mpeg'))
]

response = requests.post(add_voice_url, headers=headers, data=data, files=files)
voice_id = response.json()["voice_id"]

# get default voice settings
response = requests.get(
    "https://api.elevenlabs.io/v1/voices/settings/default",
    headers={ "Accept": "application/json" }
).json()
stability, similarity_boost = response["stability"], response["similarity_boost"]

tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream"

headers["Content-Type"] = "application/json"

data = {
  "text": "Some very long text to be read by the voice",
  "model_id": "eleven_monolingual_v1",
  "voice_settings": {
    "stability": stability,
    "similarity_boost": similarity_boost
  }
}

response = requests.post(tts_url, json=data, headers=headers, stream=True)

with open(OUTPUT_PATH, 'wb') as f:
    for chunk in response.iter_content(chunk_size=CHUNK_SIZE):
        if chunk:
            f.write(chunk)

# Retrieve history. It should contain generated sample.
history_url = "https://api.elevenlabs.io/v1/history"

headers = {
  "Accept": "application/json",
  "xi-api-key": XI_API_KEY
}

response = requests.get(history_url, headers=headers)

print(response.text)
```

You can achieve the very same result using our `python` library:
```python
from elevenlabs import clone, generate, play, set_api_key
from elevenlabs.api import History

set_api_key("<YOUR_API_KEY>")

voice = clone(
    name="Voice Name",
    description="An old American male voice with a slight hoarseness in his throat. Perfect for news.",
    files=["./sample1.mp3", "./sample2.mp3"],
)

audio = generate(text="Some very long text to be read by the voice", voice=voice)

play(audio)

history = History.from_api()
print(history)
```
