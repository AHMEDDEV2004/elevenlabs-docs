---
title: "Text to Speech tutorial"
description: "Learn how to generate speech from text"
---

The Text-To-Speech (TTS) endpoint transforms text into speech in a given voice.
The input consists of text, voice and voice settings with an option to specify model and language.

We have created a set of pre-made, ‘default’ voices which everyone can use. To get those voices use
`GET /v1/voices` without the API key as described in the [Get Voices](api-reference/voices)
endpoint documentation. If you provide the API key, endpoint will return both the premade voices
and the voices you added. This endpoint is important as it returns a voice ID for each voice.
You will need this ID to query the TTS endpoint.

Now that you know how to get all the voices, let’s see how to create a new one.
First, you need to get samples for the voice you want to add. Since no model training is involved,
there is no need to provide long samples - if they have a combined length of ≈1 min this is enough.
Their quality plays the biggest role. Once you have the samples ready, choose a name,
labels describing the voice (accent, gender, tone etc.) and create it as described in 
[Add Voice](api-reference/voices-add) endpoint documentation. If you want to edit the samples,
labels or the name of the voice, you can do this with the `POST /v1/voices/{voice_id}/edit`
endpoint. Find more information, see [here](api-reference/voices-edit).

Once you have your voice ready, get its ID from the [voices endpoint](api-reference/voices),
and you’re ready to query our TTS endpoint. First you need to decide whether you want to use
the streaming response or not. In general, we recommend streaming unless your client doesn’t
support it. Second, you need to choose your voice settings. We recommend using
[default voice settings](api-reference/voices-settings-default) before experimenting with
the expressivity and similarity settings. In the third optional step you can specify the model
and the language used for speech generation. You can get the list of available models with
`GET /v1/user` and by following the instructions [here](api-reference/user) and reading the
`subscription.available_models` response field. Each model has a list of supported languages.
Select `model_id` and language `iso_code` and you can then query the selected TTS endpoint.
You can find the streaming endpoint documentation [here](api-reference/text-to-speech-stream)
and the regular endpoint documentation [here](api-reference/text-to-speech).

We store each audio you generate together with other metadata in your personal history.
You can retrieve all your history items via [/v1/history](api-reference/history) endpoint.
We also provide endpoints for [retrieving audio](api-reference/history-audio),
[deletion](api-reference/history-delete) and [download of history items](api-reference/history-download).

Here is a `python` example implementing our guide. Get your [XI API Key](authentication/01-xi-api-key) first
and try it out!
```python
import requests
from requests_toolbelt.multipart.encoder import MultipartEncoder

# voice settings
STABILITY = 0
SIMILARITY_BOOST = 0

# streaming chunk size
CHUNK_SIZE = 1024

XI_API_KEY = "<xi-api-key>"
VOICE_SAMPLE_PATH = "<path-to-file>"
OUTPUT_PATH = "<path-to-file>"

add_voice_url = "https://api.elevenlabs.io/v1/voices/add"

data = MultipartEncoder(
  fields = {
    "name": "Voice Name",
    "labels": '{"accent": "American", "gender": "Female"}',
    "files": ("Sample", open(VOICE_SAMPLE_PATH, 'rb'), "audio/mpeg"),
  }
)

headers = {
  "Accept": "audio/mpeg",
  "xi-api-key": XI_API_KEY,
  "Content-Type": data.content_type
}

response = requests.post(add_voice_url, headers=headers, data=data)
voice_id = response.json()["voice_id"]

tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream"

headers["Content-Type"] = "application/json"

data = {
  "text": "Some very long text to be read by the voice",
  "voice_settings": {
    "stability": STABILITY,
    "similarity_boost": SIMILARITY_BOOST
  }
}

response = requests.post(tts_url, json=data, headers=headers, stream=True)

with open(OUTPUT_PATH, 'wb') as f:
    for chunk in response.iter_content(chunk_size=CHUNK_SIZE):
        if chunk:
            f.write(chunk)

# Retrieve history. It should contain generated sample.
history_url = "https://api.elevenlabs.io/v1/history"

headers = {
  "Accept": "application/json",
  "xi-api-key": XI_API_KEY
}

response = requests.get(history_url, headers=headers)

print(response.text)
```